{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":118082,"databundleVersionId":14294892,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ† DA-Lab Challenge: The \"Extreme Denoising\" Solution (Score: 2.096)\n\n# 1. Configuration & Initialization\nIn this section, we set up the environment, define file paths, and lock the random seed for reproducibility. \n\n**Key Configurations for Score 2.096:**\n* **High-Resolution Text:** Increased `TFIDF_MAX_FEAT` to **10,000** and `NGRAM_RANGE` to **(1, 3)** to capture complex technical jargon and trigrams in the prompts.\n* **Latent Dimensions:** Set `SVD_DIM` to **64**, effectively compressing the text into a dense vector space compatible with the provided `embeddinggemma-300m` metric embeddings.\n* **Stability:** Used a high estimator count for Random Forest to reduce variance.","metadata":{}},{"cell_type":"code","source":"# Cell 1: Imports and Configuration\nimport os, json, random, time, warnings, gc\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.optimize import nnls\nfrom lightgbm import LGBMRegressor\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings(\"ignore\")\n\n# ---------- CONFIG ----------\nKAGGLE_DIR = \"/kaggle/input/da5401-2025-data-challenge\"\nTRAIN_FILE = os.path.join(KAGGLE_DIR, \"train_data.json\")\nTEST_FILE  = os.path.join(KAGGLE_DIR, \"test_data.json\")\nMETRIC_NAMES = os.path.join(KAGGLE_DIR, \"metric_names.json\")\nMETRIC_EMBS = os.path.join(KAGGLE_DIR, \"metric_name_embeddings.npy\")\nSUBMISSION_FILE = \"/kaggle/working/submission.csv\"\n\nSEED = 42\nN_SPLITS = 5\n\n# --- TWEAK 1: High Resolution Text ---\nTFIDF_MAX_FEAT = 10000  # Was 5000. Capture more jargon.\nNGRAM_RANGE = (1, 3)    # Was (1, 2). Capture trigrams.\n\n# --- TWEAK 2: Restore Winning SVD ---\nSVD_DIM = 64  \n\n# --- TWEAK 3: Keep the stability boost ---\nRF_N_ESTIMATORS = 500   # Keep this high for stability.\n\nRIDGE_ALPHA = 1.0\nBIAS_ALPHA = 5.0 \nNEG_PER_SAMPLE = 1\n\n# LGBM Params\nLGBM_PARAMS = {\n    \"n_estimators\": 300,\n    \"learning_rate\": 0.05,\n    \"num_leaves\": 31,\n    \"random_state\": SEED, \n    \"n_jobs\": -1, \"verbosity\": -1\n}\n\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything()\nprint(f\"Config loaded. TFIDF({TFIDF_MAX_FEAT}, {NGRAM_RANGE}) -> SVD({SVD_DIM})\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:19:13.222758Z","iopub.execute_input":"2025-11-18T19:19:13.222983Z","iopub.status.idle":"2025-11-18T19:19:20.595003Z","shell.execute_reply.started":"2025-11-18T19:19:13.222956Z","shell.execute_reply":"2025-11-18T19:19:20.594344Z"}},"outputs":[{"name":"stdout","text":"Config loaded. TFIDF(10000, (1, 3)) -> SVD(64)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 2. Data Loading & Vectorization\nHere we load the JSON datasets and the pre-computed metric embeddings. \n\n**Preprocessing Strategy:**\n1. **Concatenation:** We combine the `prompt`, `system_prompt`, and `response` into a single text block to treat the conversation holistically.\n2. **TF-IDF + SVD:** Since we are comparing text fitness against metric definitions, we convert the text into a dense vector space. We use `Sublinear TF` to dampen the effect of very frequent terms.\n3. **Dimensionality Reduction:** We apply TruncatedSVD to both the TF-IDF text vectors and the provided metric embeddings to bring them into a shared, comparable 64-dimensional space.","metadata":{}},{"cell_type":"code","source":"# Cell 2: Load Data and TF-IDF Encoding\nprint(\"Loading data...\")\nwith open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f: train_raw = json.load(f)\nwith open(TEST_FILE, \"r\", encoding=\"utf-8\") as f: test_raw = json.load(f)\nwith open(METRIC_NAMES, \"r\", encoding=\"utf-8\") as f: metric_names = json.load(f)\nmetric_map = {name: i for i, name in enumerate(metric_names)}\nmetric_embs_raw = np.load(METRIC_EMBS)\n\ndef parse_data(raw_data, is_train=True):\n    rows = []\n    for rec in raw_data:\n        rows.append({\n            \"metric_idx\": metric_map.get(rec.get(\"metric_name\"), -1),\n            \"prompt\": (rec.get(\"prompt\",\"\") or \"\"),\n            \"system_prompt\": (rec.get(\"system_prompt\",\"\") or \"\"),\n            \"response\": (rec.get(\"response\",\"\") or \"\"),\n            \"score\": float(rec.get(\"score\", 0.0)) if is_train else 0.0\n        })\n    return pd.DataFrame(rows)\n\ntrain_df = parse_data(train_raw, is_train=True)\ntest_df = parse_data(test_raw, is_train=False)\n\n# Combine text\ntrain_texts = (train_df[\"prompt\"] + \" [SEP] \" + train_df[\"system_prompt\"] + \" [SEP] \" + train_df[\"response\"]).tolist()\ntest_texts = (test_df[\"prompt\"] + \" [SEP] \" + test_df[\"system_prompt\"] + \" [SEP] \" + test_df[\"response\"]).tolist()\nall_texts = train_texts + test_texts\n\n# --- TWEAK 1: Higher Resolution TF-IDF ---\nprint(f\"Building TF-IDF (max_features={TFIDF_MAX_FEAT}, ngram={NGRAM_RANGE})...\")\ntfidf = TfidfVectorizer(\n    max_features=TFIDF_MAX_FEAT, \n    ngram_range=NGRAM_RANGE,\n    sublinear_tf=True,\n    min_df=2\n)\ntfidf.fit(all_texts)\nX_tr_tfidf = tfidf.transform(train_texts)\nX_te_tfidf = tfidf.transform(test_texts)\n\n# --- TWEAK 2: Restore SVD=64 ---\nprint(f\"Applying TruncatedSVD (n={SVD_DIM})...\")\nsvd_text = TruncatedSVD(n_components=SVD_DIM, random_state=SEED)\nsvd_text.fit(X_tr_tfidf) \nX_tr_svd = svd_text.transform(X_tr_tfidf)\nX_te_svd = svd_text.transform(X_te_tfidf)\n\nprint(f\"Reducing Metric Embeddings to {SVD_DIM} dims...\")\nsvd_metric = TruncatedSVD(n_components=SVD_DIM, random_state=SEED)\nmetric_embs_svd = svd_metric.fit_transform(metric_embs_raw)\n\nprint(\"Shapes:\", X_tr_svd.shape, metric_embs_svd.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:19:20.596418Z","iopub.execute_input":"2025-11-18T19:19:20.596886Z","iopub.status.idle":"2025-11-18T19:19:30.045829Z","shell.execute_reply.started":"2025-11-18T19:19:20.596867Z","shell.execute_reply":"2025-11-18T19:19:30.045195Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nBuilding TF-IDF (max_features=10000, ngram=(1, 3))...\nApplying TruncatedSVD (n=64)...\nReducing Metric Embeddings to 64 dims...\nShapes: (5000, 64) (145, 64)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# 3. Feature Engineering: Metric Learning & Margins\nThis is the core logic of the solution. [cite_start]Since the goal is to predict \"fitness\" (similarity), we engineer features based on **geometric distances**.\n\n**Feature Groups:**\n* **Prototypes:** We calculate the \"centroid\" (mean vector) for every metric ID in the training set.\n* **Distance Metrics:** We compute Cosine, L1, L2, and Dot Product distances between the text vector and the target metric vector.\n* **Margin Features:** Inspired by contrastive learning, we calculate the \"Margin.\" This is the difference between the cosine similarity of the *correct* metric and the *best alternative* metric. A high margin implies the text clearly belongs to the assigned metric.\n* **Text Stats:** Ratios of prompt length to response length to capture verbosity patterns.","metadata":{}},{"cell_type":"code","source":"# Cell 3: Feature Engineering (Prototype Margins)\nprint(\"Computing Metric Prototypes from Train Data...\")\nproto_by_metric = {}\nfor mid, g in train_df.groupby(\"metric_idx\"):\n    idxs = g.index.values\n    proto_by_metric[int(mid)] = X_tr_svd[idxs].mean(axis=0)\n\nfor i in range(len(metric_names)):\n    if i not in proto_by_metric: proto_by_metric[i] = np.zeros(SVD_DIM)\n\nproto_matrix = np.vstack([proto_by_metric[i] for i in range(len(metric_names))])\n\ndef pairwise_feats(A, B):\n    dot = np.sum(A * B, axis=1)\n    an = np.linalg.norm(A, axis=1); bn = np.linalg.norm(B, axis=1)\n    cos = dot / (an * bn + 1e-9)\n    l1 = np.sum(np.abs(A - B), axis=1)\n    l2 = np.sqrt(np.sum((A - B)**2, axis=1))\n    prod = A * B; ad = np.abs(A - B)\n    return {\n        \"dot\": dot, \"cos\": cos, \"l1\": l1, \"l2\": l2,\n        \"prod_mean\": prod.mean(axis=1), \"prod_std\": prod.std(axis=1),\n        \"ad_mean\": ad.mean(axis=1), \"ad_std\": ad.std(axis=1)\n    }\n\ndef generate_features(df, X_svd):\n    row_metrics = np.vstack([metric_embs_svd[i] if i >= 0 else np.zeros(SVD_DIM) for i in df[\"metric_idx\"]])\n    row_protos = np.vstack([proto_by_metric.get(int(i), np.zeros(SVD_DIM)) for i in df[\"metric_idx\"]])\n    \n    feats_metric = pairwise_feats(row_metrics, X_svd)\n    feats_proto = pairwise_feats(row_protos, X_svd)\n    \n    # Margin Calculation\n    P_norm = np.linalg.norm(proto_matrix, axis=1) + 1e-9\n    T_norm = np.linalg.norm(X_svd, axis=1) + 1e-9\n    cos_mat = (X_svd @ proto_matrix.T) / (T_norm[:, None] * P_norm[None, :])\n    \n    row_idx = np.arange(len(df))\n    met_idx = df[\"metric_idx\"].values.astype(int)\n    \n    self_cos = cos_mat[row_idx, met_idx]\n    \n    cos_mat_temp = cos_mat.copy()\n    cos_mat_temp[row_idx, met_idx] = -1e9\n    best_other = cos_mat_temp.max(axis=1)\n    margin = self_cos - best_other\n    \n    out = pd.DataFrame(feats_metric)\n    for k, v in feats_proto.items(): out[f\"{k}_pt\"] = v\n    \n    out[\"cos_pt_self\"] = self_cos\n    out[\"cos_pt_best_other\"] = best_other\n    out[\"cos_pt_margin\"] = margin\n    \n    out[\"len_prompt\"] = df[\"prompt\"].apply(len)\n    out[\"len_response\"] = df[\"response\"].apply(len)\n    out[\"ratio_pr\"] = (out[\"len_response\"]+1)/(out[\"len_prompt\"]+1)\n    \n    return out, cos_mat\n\nprint(\"Generating Train Features...\")\nX_feat_tr, tr_cos_mat = generate_features(train_df, X_tr_svd)\nprint(\"Generating Test Features...\")\nX_feat_te, _ = generate_features(test_df, X_te_svd)\n\nX_feat_tr[\"score\"] = train_df[\"score\"].values\nX_feat_tr[\"metric_idx\"] = train_df[\"metric_idx\"].values\nX_feat_te[\"metric_idx\"] = test_df[\"metric_idx\"].values\n\nprint(f\"Feature Matrix: {X_feat_tr.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:19:30.046382Z","iopub.execute_input":"2025-11-18T19:19:30.046586Z","iopub.status.idle":"2025-11-18T19:19:30.211692Z","shell.execute_reply.started":"2025-11-18T19:19:30.046568Z","shell.execute_reply":"2025-11-18T19:19:30.211022Z"}},"outputs":[{"name":"stdout","text":"Computing Metric Prototypes from Train Data...\nGenerating Train Features...\nGenerating Test Features...\nFeature Matrix: (5000, 24)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 4. Negative Sampling (Data Augmentation)\n**Challenge:** The competition documentation notes that the training data score distribution is \"largely skewed to the high score side\". This makes it hard for models to learn what a \"bad\" response looks like.\n\n**Solution:** We generate synthetic negative samples (`is_synth=True`).\n1. We take existing valid rows.\n2. We randomly swap the `metric_idx` with a different (incorrect) metric.\n3. We assign these mismatched pairs a low score (0, 1, or 2).\n4. We re-calculate distance features for these \"wrong\" pairs.\n\nThis teaches the model to penalize semantic mismatches heavily.","metadata":{}},{"cell_type":"code","source":"# Cell 4: Augmentation\nprint(\"Creating Augmented Data...\")\naug_rows = []\nunique_metrics = train_df[\"metric_idx\"].unique()\n\nfor i in tqdm(range(len(train_df))):\n    base = X_feat_tr.iloc[i].to_dict()\n    base[\"is_synth\"] = False\n    aug_rows.append(base)\n    \n    wrong_idx = int(base[\"metric_idx\"])\n    while wrong_idx == base[\"metric_idx\"]:\n        wrong_idx = int(random.choice(unique_metrics))\n        \n    text_vec = X_tr_svd[i].reshape(1, -1)\n    wrong_metric_vec = metric_embs_svd[wrong_idx].reshape(1, -1)\n    wrong_proto_vec = proto_by_metric[wrong_idx].reshape(1, -1)\n    \n    pf = pairwise_feats(wrong_metric_vec, text_vec)\n    pf_pt = pairwise_feats(wrong_proto_vec, text_vec)\n    \n    self_cos_wrong = tr_cos_mat[i, wrong_idx]\n    cos_row = tr_cos_mat[i].copy()\n    cos_row[wrong_idx] = -1e9\n    best_other_wrong = cos_row.max()\n    margin_wrong = self_cos_wrong - best_other_wrong\n    \n    neg = base.copy()\n    neg[\"dot\"] = pf[\"dot\"][0]; neg[\"cos\"] = pf[\"cos\"][0]; neg[\"l1\"] = pf[\"l1\"][0]; neg[\"l2\"] = pf[\"l2\"][0]\n    neg[\"prod_mean\"] = pf[\"prod_mean\"][0]; neg[\"prod_std\"] = pf[\"prod_std\"][0]\n    neg[\"ad_mean\"] = pf[\"ad_mean\"][0]; neg[\"ad_std\"] = pf[\"ad_std\"][0]\n    \n    neg[\"dot_pt\"] = pf_pt[\"dot\"][0]; neg[\"cos_pt\"] = pf_pt[\"cos\"][0]\n    neg[\"l1_pt\"] = pf_pt[\"l1\"][0]; neg[\"l2_pt\"] = pf_pt[\"l2\"][0]\n    neg[\"prod_mean_pt\"] = pf_pt[\"prod_mean\"][0]; neg[\"prod_std_pt\"] = pf_pt[\"prod_std\"][0]\n    neg[\"ad_mean_pt\"] = pf_pt[\"ad_mean\"][0]; neg[\"ad_std_pt\"] = pf_pt[\"ad_std\"][0]\n    \n    neg[\"cos_pt_self\"] = self_cos_wrong\n    neg[\"cos_pt_best_other\"] = best_other_wrong\n    neg[\"cos_pt_margin\"] = margin_wrong\n    neg[\"metric_idx\"] = wrong_idx\n    neg[\"score\"] = float(random.choice([0, 1, 2]))\n    neg[\"is_synth\"] = True\n    \n    aug_rows.append(neg)\n\naug_df = pd.DataFrame(aug_rows)\nprint(f\"Augmented Data Shape: {aug_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:19:30.212556Z","iopub.execute_input":"2025-11-18T19:19:30.212825Z","iopub.status.idle":"2025-11-18T19:19:32.473403Z","shell.execute_reply.started":"2025-11-18T19:19:30.212800Z","shell.execute_reply":"2025-11-18T19:19:32.472635Z"}},"outputs":[{"name":"stdout","text":"Creating Augmented Data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e7cd03c63554be2a08c817814dff1cf"}},"metadata":{}},{"name":"stdout","text":"Augmented Data Shape: (10000, 25)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# 5. Model Training, Stacking & Bias Correction\nWe use a multi-stage stacking approach to minimize RMSE.\n\n**Stage 1: Augmented Learning**\n* We train a **Random Forest** on the dataset *including* the synthetic negative samples. This model specializes in detecting semantic mismatches.\n\n**Stage 2: GroupKFold Stacking**\n* We train **Ridge**, **Random Forest**, and **LGBM** on the real data only, using `GroupKFold` to ensure no metric leaks between folds.\n* We generate Out-of-Fold (OOF) predictions.\n\n**Stage 3: Ensemble & Bias Correction**\n* **NNLS (Non-Negative Least Squares):** We learn the optimal linear combination of the base models.\n* **Bayesian Bias Correction:** We calculate the mean error per metric group and apply a smoothed offset. This corrects systematic over/under-prediction for specific metric types.","metadata":{}},{"cell_type":"code","source":"# Cell 5: Model Training & Stacking\nfeat_cols = [c for c in aug_df.columns if c not in [\"score\", \"metric_idx\", \"is_synth\"]]\nX = aug_df[feat_cols].fillna(0).values\ny = aug_df[\"score\"].values\n\nprint(f\"Training Augmented Random Forest (n={RF_N_ESTIMATORS})...\")\nrf_aug = RandomForestRegressor(n_estimators=RF_N_ESTIMATORS, n_jobs=-1, random_state=SEED)\nrf_aug.fit(X, y)\n\nprint(\"Training Base Models & Generating OOFs...\")\nX_real = X_feat_tr[feat_cols].fillna(0).values\ny_real = X_feat_tr[\"score\"].values\ngroups_real = X_feat_tr[\"metric_idx\"].values\n\ngkf = GroupKFold(n_splits=N_SPLITS)\noof_ridge = np.zeros(len(y_real))\noof_rf = np.zeros(len(y_real))\noof_lgbm = np.zeros(len(y_real))\naug_preds_oof = rf_aug.predict(X_real)\n\nfor fold, (tr_idx, val_idx) in enumerate(gkf.split(X_real, y_real, groups_real)):\n    X_tr, y_tr = X_real[tr_idx], y_real[tr_idx]\n    X_val = X_real[val_idx]\n    \n    ridge = Ridge(alpha=RIDGE_ALPHA, random_state=SEED)\n    ridge.fit(X_tr, y_tr)\n    oof_ridge[val_idx] = ridge.predict(X_val)\n    \n    rf = RandomForestRegressor(n_estimators=RF_N_ESTIMATORS, n_jobs=-1, random_state=SEED)\n    rf.fit(X_tr, y_tr)\n    oof_rf[val_idx] = rf.predict(X_val)\n\n    lgbm = LGBMRegressor(**LGBM_PARAMS)\n    lgbm.fit(X_tr, y_tr)\n    oof_lgbm[val_idx] = lgbm.predict(X_val)\n\nprint(f\"Ridge OOF: {mean_squared_error(y_real, oof_ridge, squared=False):.4f}\")\nprint(f\"RF OOF:    {mean_squared_error(y_real, oof_rf, squared=False):.4f}\")\nprint(f\"LGBM OOF:  {mean_squared_error(y_real, oof_lgbm, squared=False):.4f}\")\n\nprint(\"Stacking...\")\nX_stack = np.vstack([oof_ridge, oof_rf, oof_lgbm, aug_preds_oof]).T\ncoef, _ = nnls(X_stack, y_real)\nprint(f\"NNLS Coeffs [Ridge, RF, LGBM, AugRF]: {coef}\")\nmeta_oof = X_stack.dot(coef)\n\nprint(f\"Applying Bias Correction (Alpha={BIAS_ALPHA})...\")\ntemp_df = pd.DataFrame({\"metric_idx\": groups_real, \"score\": y_real, \"pred\": meta_oof})\nbias_stats = temp_df.groupby(\"metric_idx\").agg(\n    n=(\"score\", \"size\"), mean_true=(\"score\", \"mean\"), mean_pred=(\"pred\", \"mean\")\n).reset_index()\nbias_stats[\"bias\"] = (bias_stats[\"n\"] * (bias_stats[\"mean_true\"] - bias_stats[\"mean_pred\"])) / (bias_stats[\"n\"] + BIAS_ALPHA)\nbias_map = bias_stats.set_index(\"metric_idx\")[\"bias\"].to_dict()\n\nmeta_oof_corr = meta_oof + temp_df[\"metric_idx\"].map(bias_map).fillna(0.0)\nmeta_oof_corr = np.clip(meta_oof_corr, 0.0, 10.0)\n\nprint(f\">>> Final OOF RMSE: {mean_squared_error(y_real, meta_oof_corr, squared=False):.4f} <<<\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:19:32.474223Z","iopub.execute_input":"2025-11-18T19:19:32.474558Z","iopub.status.idle":"2025-11-18T19:21:16.817221Z","shell.execute_reply.started":"2025-11-18T19:19:32.474540Z","shell.execute_reply":"2025-11-18T19:21:16.816452Z"}},"outputs":[{"name":"stdout","text":"Training Augmented Random Forest (n=500)...\nTraining Base Models & Generating OOFs...\nRidge OOF: 0.9420\nRF OOF:    0.9730\nLGBM OOF:  0.9928\nStacking...\nNNLS Coeffs [Ridge, RF, LGBM, AugRF]: [0.16440274 0.03906174 0.         0.82881879]\nApplying Bias Correction (Alpha=5.0)...\n>>> Final OOF RMSE: 0.5986 <<<\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# 6. Final Inference & Submission\nIn this final step, we retrain our base models on the **full** training dataset to maximize information gain.\n\n**Steps:**\n1. Retrain Ridge, RF, and LGBM on all real data.\n2. Apply the stacked weights (NNLS coefficients) derived from the OOF validation.\n3. Apply the Bias Correction map.\n4. **Clip Results:** Ensure all predictions fall within the valid `[0, 10]` range.","metadata":{}},{"cell_type":"code","source":"# Cell 6: Test Submission\nprint(\"Generating Test Predictions...\")\nX_test_real = X_feat_te[feat_cols].fillna(0).values\n\nprint(\"Retraining base models on full data...\")\nridge_full = Ridge(alpha=RIDGE_ALPHA, random_state=SEED)\nridge_full.fit(X_real, y_real)\ntest_ridge = ridge_full.predict(X_test_real)\n\nrf_full = RandomForestRegressor(n_estimators=RF_N_ESTIMATORS, n_jobs=-1, random_state=SEED)\nrf_full.fit(X_real, y_real)\ntest_rf = rf_full.predict(X_test_real)\n\nlgbm_full = LGBMRegressor(**LGBM_PARAMS)\nlgbm_full.fit(X_real, y_real)\ntest_lgbm = lgbm_full.predict(X_test_real)\n\ntest_aug = rf_aug.predict(X_test_real)\n\n# Stack\nX_test_stack = np.vstack([test_ridge, test_rf, test_lgbm, test_aug]).T\ntest_meta = X_test_stack.dot(coef)\n\n# Bias Correct\ntest_biases = X_feat_te[\"metric_idx\"].map(bias_map).fillna(0.0).values\ntest_final = np.clip(test_meta + test_biases, 0.0, 10.0)\n\n# Save\nsubmission = pd.DataFrame({\n    \"ID\": test_df.index + 1 if \"ID\" not in test_raw[0] else [r.get(\"ID\") for r in test_raw],\n    \"score\": test_final\n})\n\ntry:\n    sample = pd.read_csv(os.path.join(KAGGLE_DIR, \"sample_submission.csv\"))\n    if \"ID\" in sample.columns:\n        submission[\"ID\"] = sample[\"ID\"]\nexcept: pass\n\nsubmission.to_csv(SUBMISSION_FILE, index=False)\nprint(f\"Saved to {SUBMISSION_FILE}\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:21:16.819037Z","iopub.execute_input":"2025-11-18T19:21:16.819314Z","iopub.status.idle":"2025-11-18T19:21:34.503341Z","shell.execute_reply.started":"2025-11-18T19:21:16.819277Z","shell.execute_reply":"2025-11-18T19:21:34.502669Z"}},"outputs":[{"name":"stdout","text":"Generating Test Predictions...\nRetraining base models on full data...\nSaved to /kaggle/working/submission.csv\n   ID     score\n0   1  8.393370\n1   2  9.443199\n2   3  9.042131\n3   4  9.335973\n4   5  2.579259\n","output_type":"stream"}],"execution_count":6}]}